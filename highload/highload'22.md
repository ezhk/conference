## Go generics
[Slides](https://bit.ly/gogenhl).
Links:
- [Go generics: the hard way](https://github.com/akutz/go-generics-the-hard-way)
- [Лекция от создателей дженериков](https://www.youtube.com/watch?v=Pa_e9EeCdy8)
- [Функциональщина на дженериках](github.com/samber/lo)

Типизация:
- статическая:
  - тип указывает разработчки
  - некоторые языки могут выводить их сами
  - традиционно типа выбирается по время компиляции
- динамическая
  - тип выводит язык

Generics позволяют сокротить количество ошибок.  
Какие альтернативы были:
- ручная мономорфизация (copy => paste): при изменениях нужно менять все
- интерфейсы: нужно следить что передаем и получаем
- рефлексия (reflect)
- кодогенерация (самый лучший из перечисленных выше)
 
```
func add[T additive](a T, b T) T {
    return a + b
}
```
 
[...] — место для описания дженерика  
T — название типа  
additive – ограничение (constraint)  
  
Дженерики работают с "куском кода":
- Указывают, какие типы в этом куске должны быть "одинаковые".
- Можно использовать несколько разных дженерик-типов.
- Дженерик типы могут быть частью составных типов.
- "Куском кода" может быть функция или struct.

Дженерики можно ограничивать по типу:
```
type additive interface {
    int|uint|~float64
}
 
```
или перечислить в функции  
`func add[T int|~uint64](a T, b T) T {`

Добавлен при это токен `~`:  
~T означает все типы, которые можно свести к типу T

Дженерики можно ограничивать "сверху":
```
type Stringer interface {
    String() string
}
 
func Tos[T Stringer](s []T) []string {
```
также можно использовать comparable
```
// comparable
// == 
// !=
 
func Index[T comparable](s []T, x T) int 
```

Мы не можем использовать неограниченные дженерики:
```
func add[T additive](a T, b T) T {
    return a + b
}
 
func add[T interface{}](a T, b T) T {
    return a + b // Error
}
```

Также добавили **any**:
```
// any это interface{}, не умеет складываться
func add[T any](a T, b T) T {
    return a + b // Error
}
```

Дженерики в классах и структурах:
```
type Bucket[T any] struct {
    structField T
    ...
}
 
func (b *Bucket[T]) Add(v T) int {
    ...
}
 
func (b *Bucket[T]) Get(k int) T {
    ...
}
```

Составное (compound) параметризование:
```
func Scale[S []~E, E int](s S, sc E) S{
    r := make(S, len(s))
    for i, v := range s {
        r[i] = v * c
    }
    return r
}
```

Когда полезны дженерики?
- Функции, работающие с каналами, slice-ами, map-ами с любым типом элементов. Например, Map, Reduce и другие элементы функционального программирования.
- Структуры данных общего назначения. Например, деревья. 
  *предпочтительно использовать функции, а не методы.
- Когда код выглядит одинаково для разных типов.

Когда **НЕ** полезны дженерики?
- Когда вам нужно вызвать метод на типе данных.
Используйте интерфейсы.
- Когда имплементация общего метода имеет различия для разных типов.
- Когда действия отличаются для разных типов. Придётся использовать reflect.

Дженерики хорошо использовать, чтобы избежать повторения.  
Как следствие: не используйте дженерики пока не начнете повторяться.

**Бенчмарки**: время работы  
Дженерики работают настолько же быстро, насколько нативный код. Если есть дженерик-функция, то компилятор скомпилирует функции только для нужного типа данных.  

Дженерики это как мономорфизация, но не до конца:
- Функция генерируется под каждый GCShape

Интерфейсы работают через виртуальные таблицы, при этом они по-прежнему ощутимо быстрее, чем рефлексия.  
**Указатели для дженериков работают не так.**


## Работа с полиморфным поведением
При расширении методов интерфейса может случиться такое,
что интерфейс будет очень большим, неудобно будет добавлять реализации и пакет с интерфейсом зависит от всего на свете, также как и код сущности.  

Попробуем посмотреть как будем делать полиморфизм, если вообще нет интерфейсов:
```
"cartItems": [
    {
        "kind": "product",
        ...
    }
]
```
но в таком случае у нас неудобная JSON схема.

Одно из решений one-of семантика, где мы можем опускать описания объектов и если он есть, то с этим типов объекта и работаем через switch.

Плюсы:
- логика отдельно от данных
- простой код и объект
- простая сериализация

Недостатки:
- много зависимостей
- switch медленный
- тяжелый объект
- добавление новых опций ломает неожиданные места (паттерн Visitor)

Второе решение. Объявляем метод Kind() в интерфейсе:
```
type interface{
    Kind() ItemKind
}
```
и дальше для каждого типа определить интерфейс и дальше можно вызывать обработчик сущности — как map-набор для каждого типа данных.

Плюсы:
- логика отдельно от данных
- изолированные тесты
- легковесный объект
- независимые реализации

Недостатки:
- непрозрачный объект
- фокусы с сериализацией
- много сущностей, нетривиальный DI

**Кратко**
- локальная логика внутри пакета => обычный интерфейс
- несколько реализаций и несколько использований => делаем структуру с one-of семантикой
- много реализаций и много использований => интерфейс без методов


## gPRC
`RED = Requests + Errors (количество ошибочных запросов) + Duration`
Подсчет запросов был в defer, то есть считали не запросы, а ответа, при этом отдельный счетчик всё-равно нужен.  
`stats.Handler` позволяет навесить обработчик на разные этапы обработки запроса: TagRPC и HandleRPC. Таких событий много: InHeader, Begin... End (всего 7) — на каждый навешиваем обработчик.

Метрики:
- времена ответов с гистограммой
- статусы ответов
- количество запросов

Для замера можно использовать [opentracing](https://github.com/opentracing/opentracing-go) и `tap.ServeInHandler` в gPRC — самая ранняя точка для интеграции gRPC-Go. Логировать можно в interceptions, но не стоит этого делать в ServeInHandler.
 
- интерсепторам недостаточно точности для observability
- BinaryLog можно использовать для сырых запросов
- [кладезь знаний по gPRC](https://github.com/grpc/proposal)


## Инцидент-менеджмент (SLI / SLO / SLA)
Links:
- [Avito habr post](https://habr.com/ru/company/avito/blog/529806/)
- [SLA vs SLO vs SLI](https://www.atlassian.com/ru/incident-management/kpis/sla-vs-slo-vs-sli)

Помогает устранить источник проблемы, а не только устранить следствие.

**SLO** — декларируемый уровень клиентского качества:
- время ответа;
- количество 500-к;

**SLI** — реальное состояние метрик;  
**SLA** — что делаем, когда SLI стали хуже SLO.

Под SLA мы понимаем надежность и доступность.

Введенные термины в avito:
**NFR** — описывают нефункциональные требования работы сервисов, их качество, то, что сервис декларирует.  
Задекларируем SLO, чтобы он соответствовал 99.9% своим NFR — тогда **бюджет ошибок** 0.1%.  
То, что потратили: имеет смысл задекларировать на что именно, например, есть два фактора — ошибки и медленные ответы, неплохо бы их посчитать.  

Если бюджет превышен:
- можно пересмотреть NFR (повысить время ответа);
- выделить время в следующем спринте на техдолг;
- ввести **временный** мараторий на релизы, пока не появится бюджет на deploy.

Зачем оно надо:
- сделать поведение сервисов предсказуемым для клиентов
- дать разработчикам пространство для манёвров
- сделать микросервисы надёжными

Можно считать метрики по платежам:
- они не реактивны
- не линейно коррелируют с опытом пользователя

Как построить показательную метрику:
- давайте выберем несколько воронок и посчитаем их надежность:
  `SLI = (total = error) / total`, где total — запросы на всех этапах; не весь трафик целевой;
- учитываем конверсию между этапами:
  `SLI = (total - error - lostError)/(total+lostError)`, lostError — недополученные ошибки, исходя их ошибок на других этапах
- но воронка была не похожа на воронку, скорее на ромб, и зависит от времени суток, продуктовых измерений
- отказали от истории с воронкой — **сложно**

Решили считать надежность точек входа: какова вероятность, что в свой **первый заход** пользователь не увидит ошибки:
`SLI = SLI main * Weight main + SLI search * Weight search + ...`  
Как получить веса? Как процент от общего количества переходов.

**Надежность по точкам входа**
- легко считать;
- понятно бизнесу;
- понятно влияние пользователя;
- отображает обывательскую надежность.

Недостатки:
- покрывает лишь один аспект работы (аспект первого входа);
- требуется периодически пересчитывать страницы и коэффициенты/веса.

Чтобы строить надежный сервис надо уметь строить метрики как всего сервиса целиком, так и отдельных кирпичиков.


## DDoS
- канальный/транспортный флуд
  - тупой
    - SYN-flood
    - UDP-flood
    - прочие flood-ы
  - умнее
    - amplification (DNS, NTP, ...)
  - умный
    - обман сигнатур
    - неожиданные TCP flags
    - настройка packet rate
- прикладной
  - тупой
    - HTTP-flood
  - умнее
    - SSL renegotiation
    - show HTTP
    - pipelinening
  - умный
    - уязвимости app
    - атака на микросервисы
    - атака на СУБД

Для ботнет-нагрузки используют EC2 инстансы;  
можно использовать serverless: lambda, SQS, S3, Cloudwatch.

Канальные тонкости:
- Gbps или pps? Можно уложить firewall с pps.
- Как балансировщик выбирает ноду (бывает он предсказуемый, например по src port)
- Амплификация, IP-spoofing
- Правила TCP могут быть написаны неправильно (TCP flags) — что если вместо SYN слать SYN-ACK
- MAC-flood — переполнение таблицы CAM (CAM table overflow) и переключение switch-а в hub mode

Прикладные хитрости:
- pipelining (можно делать в рамках одного соединения не по одному запросу, а, например, 100)
- медленные запросы (slow loris, slow read/body)
- поиск бекенда без anti DDoS
  - censys/shodan/nmap/SSRF/email (можно найти бекенды не за сервисом защиты или балансером)
  - certificate transparency
  - server-side соединения
- SSL-flood (CPU, SSL renegotiation позволяет делать это без переподключения)
- эффективным может быть flood статики (с разными GET-параметрами)
- картинка-бомба, которые будет бесконечно разворачиваться в памяти: https://github.com/bones-codes/bombs
- **eJ**yrVsooz... — использование zlib — можно отправить гигабайт сжатых нулей, которые в архиве займут байт
- SQL LIKE DDoS: `%%%%%%`
- ReDoS — regular expression DoS
- flood API: например, `_limit=999999`
- бывает динамический resize размера картинки — если он не ограничивается — вектор атаки


## Go to memory
Очень похоже на статью [Allocation efficiency in high-performance Go services](https://segment.com/blog/allocation-efficiency-in-high-performance-go-services/).

Stack — как работает на коде:  
stackframe двигается по направлению стека со смещением stack pointer.

Если у нас есть указатель: увеличивает ли это стек?  
Возможен dangling pointer, когда мы формируем ссылку во внешней функции. Но компилятор отлавливает такие ссылки сразу выделяет указатель в heap.

Где же в итоге в итоге хранятся значения в golang: http://golang.org/doc/faq#stack_or_heap  
Escape analysis (`go build -gcflags="-m=2 -l"`) позволяет посмотреть где же была выделена память.

3 правила golang — 100% выделится значение на heap, если:
- вернется результат по ссылке
- значение передается как interface{}
- размер значения переменной превышает значение стека

Heap
- основан на TCMalloc (thread-caching alloc)
- память представлена во много разных слоев

Go выбирает большую часть памяти, Arena, которую go уже нарезает её. Если заканчивается arena, то выделяется ещё одна. В зависимости от платформы размер арены или 64Mb или 4Mb.  
Arena сразу поделена на 8kb страницы, и это структурой управляет heap arena.  
Фрагментация? В arena выделяются пулы для разных размеров переменных — mspan — минимальный unit в аллокаторе, который имеет meta-информацию — `runtime/sizeclasses.go`.  
Все mspan соединены в двусвязный список (`type mspan struct`). Список mspan управляется **mcentral** (из всего 67, так как всего 67 классов mspan-ов).  

Итого: есть большая арена, она делится на mcentral по классам (по 67), внутри mcentral mspan по типу класса. И внутри mspan pages.

Что делать для конкурентного доступа к памяти? На каждый тред есть cache с выделенными mspan и за этот стек отвечает mcache.

Внутри аллокатора ещё есть категории:
- tiny (<16B)
- small (16B ~ 32Kb)
- large (>32Kb)
Это не хардкод, а просто логика if-ов.

В mcache мы запрашиваем блоки из mcentral (из свободного пула).


## Postgres optimizations
Поиск пути к логам: `psql -c 'select pg_current_logfile()'`.  
Полезные инструменты:
- `pg_stat_activity()` и более удобные иструменты с выводом:
  - [db_activity.sql](https://github.com/dataegret/pg-utils/blob/master/sql/db_activity9.6.sql)
  - pgcenter
  - pg_activity
- [EXPLAIN](https://www.depesz.com/?s=Explaining+the+unexplainable)
- подкручивание IDLE параметров
  - idle_in_transaction_session_timeout
  - pg_terminate_backend(PID)
- pg_locks
  - Locktree.sql — дерево блокировок

pg_bouncer:
- show_pools
- можно посчитать количество соединений в pg_stat_activity


## Fuzzing
`f.Fuzz` позволяет передать случайные аргументы.  
```
func FuzzReverse)(f *testing.F) {
    f.Fuzz(func(t *testing.T, orig string) {
        ...
    })
}
```
Для fuzzing можно также указать набор значений.

Internals:
- testing.F
- internal/Fuzz
- runtime/libfuzzer (C-library)

Mutator генерирует эти самые входные значения, что внутри используется:
- math/rand
- crypto/rand (ходит в ОС за случайными значениями, но это медленно)
- PCG (быстрый и менее предсказуемый, нежели math/rand)

Как быть со структурами?  
Пока готового решения для структур нет (и в этом месте поведение fuzzing может ещё в дальнейшем измениться), здесь можно собрать прегенерированные значения.

Минимизация входных значений, при которой воспроизводится проблема:
- cut the tail
- remove byte
- remove subset
- replace with printable

**Выводы**
- fuzzing не для всех
- не про перекладывание JSON-ов
- другое дело protobuf-ы
- полезно, когда что-то парсим из внешнего мира
