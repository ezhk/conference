# Apache Kafka
Выключен GC в Python, тот, который работает по ссылкам.  
В dev-окружении FC включен — смотрят срабатывания и если сработал, что смотрят что именно чистил.  

Kafka — распределенная стриминговая платформа. Это cluster by design.
Есть возможность подключить connectors, чтобы сбрасывать данные в базу,
также есть стрим процессоры, но при работе на python они не поддерживаются(?).

Топик — именованный лог с последовательной записью сообщений,
может быть поделен на несколько партиций (надежнее и позволяет экономить место).  
Consumer знает offset — где он находится в этом топике.
Можно объединять consumer-ов в группы, чтобы делили offset между собой.
Не имеет смысл делать их больше, чем партиций в топике.  

Нагрузка в kafka:

- 30k RPS peak
- 12k RPS avg

1. Изначально была очередь одна, где были как ack-сообшения, так и нет,
в итоге пока ожидали ack, остальные сообщения ожидали.
2. Kafka не очень хорошо относится к сетевым задержкам, поэтому подняли
локальные kafka-кластеры. Для репликации в этом случае использовали
MirrorMaker (java-процессы с producer и consumer).

Брокеры:

- repl-factor >= 3
- min.insync.replocas = 2
- unclean.leader.election = false

Производитель (producer):

- acks = -1 | 1
- retries = MAX_INT

Контрольный канал, когда producer сообщает куда-то, что отправил сообщение,
а приемник с другой стороны проверяет полученные сообщения на своей стороне.  
Это позволяет мониторить потери, можно восстановить данные.  

Перешли с python-kafka на confluent-python-kafka:

- первая поддежривает старые кластера и написана на чистом python;
- вторая библиотека на базе C — librdkafka => быстрая, thread safe, поддерживается разработчиками kafka.

Потребители (consumers) используют обе библиотеки, в том числе и aiokafka.  

С чем встречались:

- autocommit на каждое сообщение убивал zookeeper (confluent-python-kafka), из-за большого количества ack-подтверждений;
- key типа bigint производителем «сломало» потребителя (confluent-python-kafka) — не умеют разбирать два разных типа сообщения;
- ссылка в avto-schema «сломало» потребителя (python-kafka & fast-avro)

Kafka:

+ мощный и удобный инструмент
- ничего не работает из «коробки»


# Django under microscope
execute_from_cammand_line — дверь текущего процесса, точка входа, там происходит:

- bootstrap: чтение конфига;
- ищем django_settings_module;
- создаем конфиг для каждой из INSTALLED_APPS (там происходит импорт модулей, sanity-check для моделей/админки, без коннектов к базе).

Затем попадаем в модуль, который по аргументам командной строки пробует узнать, что мы хотим запустить,
в нашем случае runserver (django-admin runserver). Дальше идем в модуль runserver и попадаем в def handle
внутри class Command — там устанавливается WSGI сервер и выполняй в event_loop запросы.  
WSGI ждет на вход некий словарь с заголовками, а дальше мы формируем ответ с помощью get_response (__call__ в WSGIHandler).  
Внутри происходит вся машинерия Джанги:

- WSGIRequest описано поведение для различных типов запросов;
- дальше запрос попадает в MIDDLEWARE (позволяет оборачивать другие функции, что-то типа декоратора),  
  берем изначальный функцию, например, get_response, её оборачиваем в middleware, то есть по сути некоторое  
  оборачивание view-проекта;
- модуль routing — где мы решаем какой handler вызвать для конкретного запроса (на основании URL-а / request path info),  
  и дальше вызывает эту view с запросом;
- resolver — идет по URL-у и собирает аргументы для нашей view;
- дальше попадаем по view — в самом простом представлении функция, возвращающая ответ;
- оботка формы.

Сама по себе форма должна быть прочитана из сокета, form-data — bites-stream,  
в котором описаны разделители, который мы можем прочитать и что-то сделать.  
Парсер в этом случае состоит и chunk-итератора, затем это оборачивается в LazyStream,  
который делает его как file-object, а дальше оборачивается в Parser.  
Дальше форма должна сохраниться в БД с помощью модуля Queue, который оборачивает запрос в SQL синтаксис.

После получения SQL — модель стучится в DBRouting, берется wrap-ер над драйвером БД,  
и на выходе универсальный объект для работы в Django (своя обертка для корсоров, например).  
Этот же wrapper будет читать ответ из БД и соберет на выходе инстанс модель.  

Чтобы что-то сказать пользователю мы должны вернуть тело, с помощью шаблона,  
специфичного — там подключаются регулярные выражения (Lexer делает из списка данных набор токенов),  
дальше токен передается в теговую ноду и всё это передается в парсер. На выходе обработчик тега дает  
какую-то ноду с методом render.  

Ответный путь http responce: view -> middleware -> iter WSGI handler -> write to socket.  
Итого регексы встречаются не только в URL path, но и в процессинге шаблонов.


# Refactoring
Automated code quality: linters — pylint / mypy / black / coala.  

Pylint and MyPy:

- lints code according to some reules
- stablised practice
- bare minimum
- mypy checks if annotations follow typing
- opt-in ib a per-functions basis
- easy to implement slowly

Black:

- keeps code style consistent
- simple to run
- no args about unimportant things
- keeps the same interpreter output

Coala:

- more advanced tools
- very modular, a framework for other tools
- easy complexity checks
- can auto-fix cide locally

Levels of code smells:

1. couple of line of code, scope nonexistent
2. architecture mistakes / larger scope and respawning
3. easy to notice, impossible to remove / "lets write everything"

SonarQube:

- static analysis of code
- analyses: bugs, code smells, known security oversights.


# Deep learning without frameworks
Authors book «Grokking deep learning.»  
[slides](http://carnes.cc/moscow)

```
import numpy as np
weights = np.array([0.7, 0.2, -0.5])
alpha = 0.1

streetlights = np.array([
    [0, 0, 1],
    [0, 1, 1],
    [0, 0, 1],
    [1, 1, 1],
    [0, 1, 1],
    [1, 0, 1],
])
walk_vs_stop = np.array([0, 1, 0, 1, 1, 0])

for iteration in range(40):
    error_far_all_lights = 0
    for row_index in range(len(walk_vs_stop)):
        input = streetlights[row_index]
        goal_prediction = walk_vs_stop[row_index]
        prediction = input.dot(weights)

        error = (prediction - goal_prediction) ** 2
        error_far_all_lights += error

        delta = prediction - goal_prediction
        weights = weights - (alpha * (input * delta))

        print("prediction: " + str(prediction))
    print("weights: " + str(weights))
    print("errors: " + str(error_far_all_lights))
```


# Линтеры
[wemake-python-styleguide](https://github.com/wemake-services/wemake-python-styleguide)
Задача линтеров:
- делать код похожим
- облегчить жизнь на ревью
- найти то, что сложно найти

Некоторые проверяют только стиль — flake, black,  
другие проверяют семантику — pylint,  
а некоторые делают type checking — pyro.  

Хороший путь кода в production:  
линтеры > тестирование > code review (который автоматизировать невозможно).  

Pylint:

- смешивает всё в одно: есть проверки синтаксиса, type check (models.objects может сказать, что нет такого plugin-а)
- собственная реализация abstract syntax tree

SinarQube:

- отдельный инструмент, написанный на java, который крутится в стороне
+ есть очень крутые проверки

Flake8:

- в нем мало правил
+ очень простой
+ но в нем много plugin-ов

Так может взять flake8 и дописать необходимые плагины?  
Линтер должен проверять много, не должно быть правил «если сильно хочется, то можно».  

Что использует wemake-python-styleguide:

- flake8
- eradicate
- isort
- bandit (находит скрытые пароли)
- ...

Проверяют:

- сложность:
- cyclomatic complexity (много различных вложений for-ов, if-ов)
    - arguments (количество аргументов)
    - cohesion (насколько связан класс внутри — как часто в классе его методы) / coupling (внешние связи)
    - jones complexity (определение сложности строчки)
- имена
- консистентность (если ты где-то пишешь так, везде пиши так)
- лучшие практики

Что ещё посмотреть:

- [layer-linter](https://github.com/seddonym/layer_linter) — что можно импортировать и что нельзя
- [cohesion](https://github.com/mschwager/cohesion) — проверяет насколько связан класс внутри
- [vulture](https://github.com/jendrikseipp/vulture) — поиск неиспользуемого кода в Python
- [radon](https://pypi.org/project/radon/) — подсчитывает различные метрики кода


# Система ML-моделирования финансовых показателей компаний
Jupyter — стандарт для ML где в одном интерфейсе есть всё:

- доступ к FS
- управление платформой
- доступ к данным
- сохранение истории моделей

Репозиторий моделей:

- репозиторий кода
- файловое хранилище (HDFS, EFS)
- репозиторий объектов (?)

Что сделали:

- дали пользователю UI
- стандартизация задач (обучение, прогноз...)
    - задачи независимы друг от друга
    - задачи должны иметь автономные чтение/запись
    - нет конкурентной записи результатов
    - могут выполняться длительное время
    - отдельная задача — отдельный процесс python
- специализированная библиотека ML
- интеграционная обвязка


# 50 оттенков Celery
Требовалось:

- запускать фоновые задачи:
    - email, push;
    - обновление данных;
    - специфические проверки, например, проверка на фрод
    - maintance задачи
- пакетная обработка задач:
    - что и предыдущее, только массовое
    - перерасчёт данных
- extract transform load:
    - загрузка данных из внешних источников
- асинхронный API: использование polling механизма с обновлением стейта в БД
- периодические задачи
- триггерная архитектура (выполнение таска по какому-то событию)

В качестве мониторинговой системы Sentry, поэтому важна интеграция в том числе с ней.  
Какие есть варианты решения задач:

- [uwsgi_tasks](https://github.com/Bahus/uwsgi_tasks):
- celery
- rq
- [dramatiq](https://dramatiq.io) — как продолжение celery, заточен на производительность

Redis тоже может быть как message broker и более производителен, чем rabbitmq с celery.  
Используют:

- prefork pool
- не используют result backend

Рекомендации:

- минимум логики в задаче, используют задачи, только как запускаторы кода;
- простые объекты в параметрах:
    - сообщение занимает меньше памяти;
    - проще сериализовать;
    - данные могут быстро устаревать;
    - данные явно сохраняются и могут быть использованы при retry;
- идемпотентные задачи (при повторном выполнении кода никаких сайд-эффектов быть не должно):
    - проверяйте, что входящие данные актуальны;
    - используйте транзакции;
- обратная совместимость: может быть когда старый воркер принимает новый код producer:
    - используйте резиновую сигнатуру (**kwargs)
- timeout-ы:
    - soft_limit_timeout
    - expires
    - eta (countdown) + visibility timeout
    - должны быть проставлены timeout-ы по умолчанию
- retry policy:
    - не завалить внешний сервис ретраями
    - явное указание retry_backoff, retry_jitter, max_retries
- утечка памяти: worker_max_memory_per_child
- приоритет выполнения задач:
    - priority можно указать для каждой задачи (для redis создается новая очередь)
    - создают воркеры для celery с разной важностью: high_prio, low_prio
- ETL:
    - каждая задача получает на вход результат предыдущей задачи:
      есть функция chain, которая из 3 задач делаем pipeline
        - исключение возникает остановку всего chain-а
        - сложно катомизировать
        - все аргументы передаются в одном (!) сообщении

Task flood — когда большая задача, например, рассылка по email-ам:  
большое потребление памяти и задача может быть убита по timeout с delay().  
Конкурентность воркеров помогает снизить нагрузку на сервис, но не решает проблемы задачи генератора.  
Пошли по пути, что не нужно прямо сейчас выполнять большое количество задач  
(celery.chunks не изменил ситуацию, потому что задача всё-равно загружает всех пользователей).  
Выставляли rate_limit, но оказалось, что он не для задачи, а для воркера.  

В итоге написали свою библиотеку [chinktificator](https://github.com/Bahus/celery-chunkify-task) (запускает задачу только для определенного chunk-а задач).  

Celery CLI для мониторинга:

- inspect - информация о система
- control - управлять настройками системы

Celery flower умеем простые графики, но очень простой.  
Для мониторинга заисользовали [celery-prometheus-exporter](https://github.com/Bahus/celery-prometheus-exporter).  

Чего не хватает в celery:

- автоматическая перезагрузка кода
- метрики для prometheus из коробки
- rate_limit для одной задачи, а не для воркера


# Ошибки Django-приложений
DRF фреймворк для Django, который позволяет использовать endpoints django по REST протоколу.  
Основной потребитель API — frontend — нужно стандартизировать API.  
Создавать документацию на старте проекта — очень важно, так как облегачает порог входа новых участников:  
[swagger](https://petstore.swagger.io/) в кажется описания взаимодействия с API.  

Почему лучше использовать API, вместо django-шаблонов:

+ API универсален
+ API быстрее шаблонов
+ легко дорабатывается
+ можно использовать для интеграций и обмена данными
+ легче деплоить

Что нужно сделать на старте проекта:

- аудит кода
- проверить endpoints
- установить систему анализа кода (например, silk — сохраняет весь запрос в БД, её не стоит ставить на 100%)
- проанализировать запросы в БД
- подстроить карту хотспотов

Логирование:

- ELK (or [newrelic](https://newrelic.com/))
- zabbix
- sentry

Итого:

- документация
- логи
- оптимизация hotspot
- договоренности об API внутри компании


# Beyond jupyter
Python-скрипт для обработки pipe-line-ов: make_inserts(tranform(clean(load_from_db()))).  
Что делать, если какая-то проблема посередине?  

Какие есть планировщики задач:

- [celery](http://www.celeryproject.org)
- [rq](http://python-rq.org)

Очереди хорошо, когда множество независимых легковесных тасков.  
Проблемы с планировщиками:

- управление зависимостями
- проверка общего состояния: завершится ли процесс?
- воспроизводимость результатов

Второй подход — streaming-сервисы:

- ELK: хорошо для логов, но при сложных пайплайнах — большое количество конфигов
- kafka / confluent stack: когда нужна обработка в близком к реальному времени, zookeeper

ETL-процесс:

- extract — извлечение данных из источника
- transform — преобразование данных (маппинги, очистка, комбинирование данных из разных источников)
- load — загружить данные в БД

ETL — хорошо:

+ когда необходимо управлять зависимости частей pipe-line
+ управление и мониторинг процесса, который может длиться днями
+ пайплайн включает в себя человека, то есть можно в середину добавить валидацию данных человеком
+ возможно продолжить с того места, где упало
+ возможность перепрогнать процесс на исторических данных
- не для реального времени
- при взаимодействии нескольких систем — необходимо поддерживать общую модель данных

Средства для того, чтобы ETL-ить:

- framework [Luigi](https://github.com/spotify/luigi):
    - подкласс класса Task
    - очень мало зависимостей (tornado, python-daemon)
    - до десятков тысяч задач, но сложно масштабировать
    - на pure python, концепция target, более жесткая структура
- [Airflow](https://airflow.apache.org/):
    - логика просто collable, управление зависимостями отдельно
    - можно использовать бекендом celery
    - есть тестирование, логгирование, масштабирование и админка

Airlow хранит состояние в базе, а luigi всё хранит в target-ах.


# Selenium
Выполняет задачу автоматического выполнения каких-то действий в браузере.  
Работает на Java, вызывает браузерный процесс с javascript-ом и там выполняются какие-то действия,  
но при этом нет доступа к файловой системе, поэтому нет возможности проверять действия со скачиванием — это изначально.  

Сейчас есть: selenium server > web driver binary > browser.  
Установка selenium server очень нетривиальна.  

Чтобы оградить инстансы браузера — стоит использовать API selenium со связкой с Docker: Selenium API <> docker <> browser.  
И это не реализовано в стандатном selenium server. Так появился selenoid, написанный на go.  

Пример конфигурации для selenoid:

- [конфигурация браузера browser.json](https://aerokube.com/selenoid/latest/#_browsers_configuration_file)
- [набор образов браузеров](https://aerokube.com/selenoid/latest/#_browser_image_information)
- [исполняемый go-бинарник ./selenoid](https://github.com/aerokube/selenoid/releases)

``$ ./selenoid -conf browser.json``

Но есть упрощенная возмодность запуска — [CM](https://github.com/aerokube/cm/releases):

```
./cm selenoid start --vnc
./cm selenoid-ui start
```

Во время операции скачаются необходимые контейнеры и на выходе мы получаем готовый docker-container.  
Теперь можем запустить наш тест: [python-demo-test](https://github.com/vania-pooh/python-demo-test).


# Make python fast again
[github](https://github.com/yefremat/mpython2018)  
[PerformanceTips](https://wiki.python.org/moin/PythonSpeed/PerformanceTips)  

Профайлинг — не забываем про него.  
Этапы оптимизации кода:

- оптимизация логики/ускорение обработки: при вычислении чисел Фибоначчи нашли формулу Бине и ускорились на 2 порядка
- оптимизация записи: запись по выходу из циклов
- оптимизация чтения: групповая обработка операций
- эффективность десериализации объектов: вместо json могут быть другие похожие библиотеки, например ujson или simplejson
- могут ли помочь треды? Если AIO операции, то да
- масштабирование с запуском большего количества копий/инстансов (есть шанс упереться в AIO)
- асинхронное выполнение (asyncio, [uvloop](https://github.com/MagicStack/uvloop))
- SQLAlchemy Core API, в сторону отказа от ORM / использовать raw SQL вместо существующих библиотечных вызовов
- использование внутренних очередей (между процессингом и записью свои воркеры, как один из вариантов)
- стоит подумать про препроцессинг, про агрегацию
