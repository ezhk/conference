# Эксплуатация contaier-based-инфраструктур
До микросервисов — всё на отдельном железе, проблемы:
- сложно разрабатывать
- сложно управлять зависимостями

Микросервисы:
- траблшутить стало проще
- нет зависимостей
- простой сервис вместо монолита

В коде были вызовы функций сторонних модулей, стали сетевые вызовы.
Этапы развития:
1. infrastructure as a code — завиксировать все взаимодействия
2. docker
3. kubernetes

Docker:
- было сложно собирать deb/rpm
- уложнили сеть, чтобы не было коллищий
- внутри: namespaces, cgroups + tooling
Контейнер легче VS, ниже overhead по CPU, например.

Текущее настоящее:
- docker-, kube-  — на отдельном облаке железа
- БД также на отдельном железе
- resource-intersitive приложения также на отдельном железе
В результате абсолютной простоты так и не получилось до конца.

Какова финальная задача:
- распределение ресурсов между сервисами
- как избежать простаивания ресурсов
- понимание дополнительной ёмкости

Cgroups:
- **CPU**:
  - shares — пропорция выделения CPU time
  - quota — ограничение CPU времени в ед. реального времени
    если процесс потратил свое время, то ресурсы не выделяются — throttling
    docket --cpu-period --cpu-quota
  - cpusets — привязка процессов к конкретным ядрам
Не забываем performance в scaling_governor (пример:
один процесс отвечал медленнее до запуска второго процесса).

Стабильность с квотами
- знаем предел производительности
- можем посчитать утилизацию docker/<id>/cpiacct.usage
- если уперлись в quota — растет nr_throttled и throttled_time docker/<id>/cpu.stat

Как распределять ресурсы:
- делим сервер на слоты без overselling для latency-sensitive сервисов (quota)
- для повышенной нагрузки готовим ещё столько сервиса, чтобы потребление < N%

Но фоновые сервисы остаются: слотам выставляем максимальный --cpu-shares,
чтобы фоновые задачи были менее приоритетнее — *не помогло*.
CFS:
- достаточно дискретен, CPU time выделяется слотами
- sysctl -a|grep kernel.sched_
- изменение интервала квоты с 1ms > 50ms — *помогло*.

- **Memory**:
  - <cgroup>/memory.stat
  - можем ограничить размер памяти группой
  - можем узнать сколько съел page_cache
  pcstat <filepath> — проверка наличия файла в кеше.
  docker --memory

- **blkio**:
  - всё по аналогии CPU
  - лимиты по iops/traffic на r/w
  - можно настроить для конкретных дисков
  docker --device-read-iops
  Метрики: cgroup/blkio/<id>/blkio.throttle.io_services
  docker --blkio-weight

  IO sched:
  - cfq настроить не получилось
  - deadline лучше, когда важно latency > `echo deadline > queue/scheduler`
  Результаты: работа приоритетов зависит от планировщика IO.
**«Perf очень крутой.»**

# Linux kernel TLS & HTTPS
HTTPS DDoS:
- ассиметричный DDoS (компрессия, TLS) — сервер тратит больше ресурсов, чем клиент
- множество IP-адресов — сложность фильтрации (используется machine learning)
- Машинное обучение — временной лаг при срабатывании
TCP stream filter:
- iptables strings (сканирование заголовков, URI, Cookie),
  но при пересечении границы пакета нужными данными это не работает
- web accelerator (он парсит заголовки, но не подходит для фильтрации)
- IPS/IDS (фильтрация заголовков от узлов),
    - не собирает трафик, не участвует в его приеме
    - также нужно терминировать SSL — двойная обработка запроса

Какая система нам нужна:
- терминация TLS
- должна быстро парсить HTTP
- должны быть встроены механизмы фильтрации
- быстрый web-cache: следствие того, что есть
  проседание по классификации машинного обучения,
  поэтому на первое время надо успевать обрабатывать
  запросы; также могут быть и будут ложные срабатывания.

Web-accelerator:
- хорошо отрабатывает контент
- умеют хорошо rewrite/ACL
- делают фильтрацию
но все они проектировались давно, фильтрацию
делают не очень хорошо (http flood их положит).

Kernel-mode web-acc: TUX, kHTTPd
- те же сокеты и треды
- zero-copy > sendfile() (тут от них отказались)

Почему работают мелденно web-accelerators:
- медленный интерфейс сетевого IO
- есть копирование системных вызовов
- иногда блокировать дороже, чем отдать из кеша
- используют libc вызовы или медленные FSM

Fast network IO: kernel bypass подходы
- netmap (10Gb per core)/DPDK/PR_RING,
  быстро, но на очень простых приложениях,
  пока не нужно парсить заголовки
- TCP/IP стеку нужны механизмы синхронизации и быстрая аллокация памяти,
  в user-space есть read-copy update, но он медленный;
  spinlock сделал в libc плохо, в ядре более прогрессивный MCS (учитывает
  конкуренцию между ядрами);
  нежно реализовать buddy-allocator

Kernel SSL/TLS, история:
- KSSL, портированный openssl в ядро linux
- solaris ssl proxy, но в основном для старых CPU-архитектур

Ядро 4.13: facebook/redhat добавили поддержку,
он может оффлоадить только стрим (только симметричное шифрование),
**не умеет handshake**. CONFIG_TLS нужно дополнительно включать.
Mellanox использует этот же интерфейс kTLS.
Что сейчас плохо сделано:
- facebook решал свою задачу с установленными сессиями,
  их не очень интересовали handshake новых пользователей,
  а для нас они важны
- TLS 1.3 умеет быстро устанавливать handshake (1-RTT handshake),
  но по-прежнему есть TLS 1.2
- TLS renegotiation (клиент всегда может попросить это сделать)

Сейчас в процессе:
- встроенный http парсер
- HTTPS работает также как и TCP/IP

Большой недостатоток user-space HTTP proxy:
множественное копирование данных, в том числе и из-за переключения контекста ядра.

Синхронные сокеты:
HTTP pipeline здорово увеличивает производительность, но нужны локи при доступе в TCB.
Но ходить к локам с разных ядер долго.
Быстрый трансфер inter-CPU — используется ring-buffer.

skb page allocator, zero-copy HTTP msg:
например, нужно изменить заголовки пакеты:
мы разделяем контент на 2 и посередине правим
заголовок и склеиваем 3 блока — это быстрее
копирования skb.

В процессе работы также:
- TLS 1.3 puzzles > serverhello:
  - cookie (simple echo)
  - sha 256/512
- sticky cookie
- zero-copy space transfer

[Tempesta](https://github.com/tempesta-tech/tempesta)

# High speed load balancing from the linux kernel
[Zevenet](www.zevenet.com)

Network layer filtering:
- raw prerouting
- mangle prerouting > marking
- nat prerouting > rewrite destination
- routing
- nat postrouting > rewrite source

Using *nftables* for different expressions:
  nth, random, hashing, etc.
  Change dst mac-addresses in this case.  
LVS-NAT/DSR slower than NFT-NAT/DSR.

*zvnftd* using nft, make healt check possible.
[github](https://github.comf/zevenet)

# Dataplane networking acceleration woth OpenDataPlane
[ODP](https://github.com/Linaro/odp)

Почему dataplane уходит в user-stack и не делается в ядре linux:
- задержки (возможно процессор уже занят обработкой прерывания или когда сработает softirq)
- проблема копирования пакетов из области ядра в приложение
- сложная манипуляция с skbuf
- если крешиться компонента ядра — это хуже креша приложения

Dataplane types:
- hardware
- software
- software defined — приложение определяет функциональность,
  и если оборудование может сделать это в железе, то оно
  делается там

OpenDataPlane — описывает API, как управлять железом, чтобы
писать кроссплатформенные приложения.
Похожие проекты, но ориентированные больше на работу с сетевыми картами:
- PFring
- Netmap
- DPDK

Bottleneck — PCI-шина, express 5.0 имеет пропускную способность 60Gb/sec.

ODP components:
=RX=> PKTIO (packet IO) => classificator => набор очередей и их процессинг (odp_thread) => traffic manager => PKTIO (возвращение их в линию) =TX=>
Модель ODP:
- основной процесс выделяет память и настраивает компоненты
- воркеры, процессят трафик на определенном ядре

ODP внутри:
odp_pktio_t — абстрактный тип, достаточно указать его имя
Тип так выбран потому, что у разных вендоров по-разному обозначаются
устройства ввода-вывода. Похож на абстракцию skbuf в Linux.

Базовый компонент ODP — очереди, куда пакет попадает в соответствии со своим flow.
Очередь software, если оборудование не поддерживает аппаратную очередь.
Они, в свою очередь, могут быть параллельные, или ordered — с сохранением порядка.

Режимы работы:
- без участия sched, когда берем пакет и перемещаем его в другую очередь
- odp_schedule() — также может быть реализован аппаратно

Классификатор — блок, который стоит на входе;
внутрь можно загружать правила, как пакеты будут распределяться на очереди.
На выходе стоит traffic manager, который делает QoS, например, wred.

OpenFastPath.org — IP stack on ODP
https://github.com/OpenFastPath/nginx_ofp

# Настройка kubernetes: tips & tricks
Как работает kubernetes: для разработчика — есть код, kubectl и облако.
На самом деле:
- control plain — набор процессов для обеспечения работы кластера
- worker node — ноды, где работают приложения

*Control plane*
- apiserver — все компоненты через него, это stateless процесс,
  его можно спокойно scale-ить; он открывает REST API, можно
  подписываться на обновления по фильтру — что и делают все компоненты.
- etcd — основное хранилище кластера не только текущего, но и желаемого.
  Эту компоненту надо стазу расширять.
- sheduler — он просто прописывает соответствующую ноду в соответствии
  со спецификацией.
- controller manager — отвечает, чтобы желаемое состояние сервиса
  соответствовало действительно.
- dns
- сетевой addon (calico)

*Worker node*
- kube-proxy — подписывается на одновления apiserver-а, мониторит изменения,
  конфигурирует сеть (правила iptables)
- kubelet — работает непосредственно с движком контейнера (create/delete container)

kubectl работает также с apiserver.

За чем следим:
- ноды: CPU, net, RAM
- инфраструктура: apiserver, etcd, scheduler

Проблемы:
- «нехватка» ресурсов — стало больше сущностей,
  за счет простоты разворачивания разработчики активнее
  создавали dev-окружения: kube-scheduler.
  *Нужно предвалидировать и устанавливать requests в зависимости от окружения*
  Использовать LimitRange — наиболее правильный (объект в котором можно
  задать число request-ов по умолчанию), выделять и ограничивать namespaces,
  написать свой linter.
- высокий и «рваный» latency, обратить внимание на performance в scaling_governor
- сетевые потери: под удар попадает dns (внутри resolv.conf добавляется 3 домена,
  поэтому каждый запрос получим 6 обращений — nsdomain и A запросы)
- деградация, когда свыше 100 pod на хосте:
    $ kubectl get pods
    ...
    status
    container creating
  в логах при этом operation timeout: context deadline exceeded.
  Приняли решение разбивать хосты: запуск vms как k8s worker nodes.
  Запустили kvm-машины (для запуска множества конейнеров О_о).

Мониторинг:
- kube-apiserver:
  - rate запросов
  - процентили
  - rate ошибок по запросам
- kube-dns:
  - dnsmasq: кеш перед kube-dns
    $ ps axuww
    ...
    dnsmasq --cache-size 5000
- kubelet:
  - rate запросов и ошибок

*Prometheus* умеет мониторить все компоненты, как worker node, так и control plane;
он умеет ходить в /metrics — а все компоненты умеют корректно отвечать на этот запрос.

kubernets — стоит воспринимать как ОС для кластера.
При работе с kvm стоит использовать virtio в качестве сетевой подсистемы.

# Блокчейн. Lego для интересующихся
Классические банки — большие очереди, частично решают проблемы интернет-банки.
Но хочется больше прозрачности, понятности, чтобы просто взять и одолжить
людям деньги.
Наш банк — это точка входа, но хорошо бы наши действия где-то запаковать —
объединять в транзакции, поскольку их много. Также мы хотим проверять транзакции
большими пачками.
block (transactions (action)) — то есть блок включает транзакции, а те — абстракции.
В итоге мы начинаем по сети передавать не деньги, а транзакции, чтобы избежать
ситуации откуда и куда пришли данные — transaction pool, у которого есть время
жизни и размер. Сеть должна быстро договориться с теми, кто крутит public node.
Если транзакция не укладывается в лимиты — она выбрасывается.

Дальше нодам надо договориться — consensus: pow, pos, dpos, в итоге система
сформировала следующий блок на основе transaction pool и применяет его.

Помимо этого для каждого блока вычисляется хэш с учетом предыдущих,
в итоге у нас всегда есть зависимость:
{-; block0; hash1}
{hash1; block1; hash2}

Также в блокчейнах есть индекса (в некоторых из них их надо
предопределить), единственный способ его наполнить — просматривать
на каждом блоке. Классические индексы — прямой и обратный — есть
хеш от блока и его номер; также есть timestamp.

Блокчейн — некоторый набор алгоритмов.
https://github.com/kotbegemot

# Развитие БД в Dropbox
Все клиенты пользуются API, который взаимодействует с
metaserver (хранится информация о файле), blockserver (где хранится о block-ах).
Клиент обращается к metaserver за получением, там есть кеш,
blockserver для записи, блоки хранятся где-то в block storage.
Всё это на mysql.

Metaserver изначально хранил информацию в Global DB, в дальнейшем шарды разъехались.
Edgestore — графовый сторадж — абстрагирует mysql от клиентов и использует также cache,
эту сущность использует metaserver.
Blockserver расширился до Magic pocket.

Базовая топология
DC1:                  DC2:
master --> slave ---> pseudo master
       |-> slave          |-> slave
Magic pocket дублирует данные среди зон.
Итогда pseudo master может быть master и тогда master-master репликация.

Сингл инстанс (под mysql сразу выдяляется почти вся память = 310GB):
+ просто оперировать
+ простые фейловеры
- операции над один серверов
- шарды влияют друг на друга
Сейчас запускают мультиинстанс:
+ операции над инстансом
+ шарды почти не влияют друг на друга
+ микс разных категорий и классов
- сложнее управлять
- сложнее фейловеры

В процессе развития появился AFS — абстракция к zookeeper.

Любую базу можно восстановить за любой период времени на последние 6 дней.
Проверяют бекапы, выборочно восстанавливают набор реплик.
Используют xtrabackup.
Бекапят binlog.

Автоматизация:
- auto-replace (сервер потерялся и надо решить что произошло как можно быстрее)
  Каждый сервис шлет heartbeat. В loop проверяем hearbeat, если достигнут threshold,
  то с сервером проблемы; затем проверяется есть ли запись и какая-либо активность;
  3 шагом проверяется не было ли изменений в топологии, вдруг сервер только добавлен,
  сколько таких одновременных срабатываний произошло.
- DBmanager — в нем есть логи, планировщики задач, точки синхронизации;
  в нем есть клиент и есть планировщик для запуска операций;
  на каждом хосте есть dbagent — куда передается то, что нужно сделать на сервере;
- naoru (небольшие задачи, типа замены дисков)/wheelhouse (для долгих процессов, типа обновления ядер на серврах)

Инциденты доставляются через PagerDuty.
Каждый инцидент разбирается, их нужно отрабатывать.
Принудительно тушат какую-то часть production серверов и проверяют
сценарии работы. Приложения должны закладываться, что часть может
отказать.

# Технологии хранения для больших проектов
Ceph — обеспечивает высокую достпуность данных,
  система обещала быть масштабируемой, гибкость.
  - Трехкратная репликация — очень дорого.
  - От EC пришлось отказаться.
  - Производительность записи 4-6GBps.
  Предложенное решение — flash cache.

3 типа ФС в качестве больших кластерных систем:
- параллельные
- кластерные
- распределенные (к этому стремятся также первые два)

Общий набор функций таких ФС:
- прозрачность
- консистентность данных
- масштабируемость
- устойчивость к отказам
- балансировка нагрузки
- доступ к данным

Когда плох Shared Nothing (архитектура системы, когда нет
общих ресурсов, когда общая только сеть):
- стоимость хранения критична (так как надо на 2-3 узла записать данные)
- высокая интенсивность записи
  - загружается сильно interconnect
- нагрузка
- требуемая производительность превышает производительность узла

Параллельные ФС:
+ обеспечивают доступ к одному набору данных от множества серверов
+ клиентское ПО эффективно параллелит нагрузку
+ большие размеры кластеров
+ зачастую — ассиметричная архитектура
В качестве примера Lustre.

**Lustre** обладает двумя основными политики stripe (файл разбивается на чанки):
  RR (когда чанки случайным образом размазываются на ноды),
  QoS (чанки распределяются по наименьшей заполненности, включается после RR).
BeeGFS имеет API для приложений.
Типичные ошибки Lustre:
- использование lustre в качестве основного хранение
  - оптимизация под высокую производительность
  - ребалансировка кластера

Короткие тезисы про другие ФС:
**IBM GPFS** — привязка к оборудованию.
**GfarmFS** — на множестве узлов ставятся доп. модули, которые помогают
развернуть над локальными ФС некую глобальную сущность.